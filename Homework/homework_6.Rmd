---
title: "Homework 6"
author: "Thomas O'Leary"
output:
  rmarkdown::html_document:
    theme: lumen
    number_sections: false
    toc: true
    toc_float: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
```

# Fitting Data Distributions

This exercise teaches you how to compare a histogram of continuous (or integer) data to the probability density functions for different statistical distributions.

1. $\checkmark$ Set up a new `.Rmd` file for this exercise. Copy and paste the code below into different code chunks, and then read the text and run the code chunks one at a time to see what they do. You probably won't understand everything in the code, but this is a good start for seeing some realistic uses of `ggplot`. We will cover most of these details in the next few weeks.

2. $\checkmark$ Once the code is in and runs, try running this analysis on your own data (or data from your lab). Find a vector of data (of any size), set it up in a `.csv` file, and read the data into a data frame with this code chunk: Lauren will be able to help you if you are having trouble reading in the data.

3. $\checkmark$ Once your data are in, go ahead and comment out the "fake data" that are simulated in the chunk below. At that point, if you compile the entire file, it should run all of the code on your own data. Be sure to add comments to the code and commentary to the `.Rmd` file so that you can go back to it later and understand and use the code in your work.

4. $\checkmark$ Take a look at the second-to-last graph which shows the histogram of your data and 4 probability density curves (normal, uniform, exponential, gamma) that are fit to the data. The `beta` distribution in the final graph is somewhat special. It often fits the data pretty well, but that is because we have assumed the largest data point is the true upper bound, and everything is scaled to that. The fit of the uniform distribution also fixes the upper bound. The other curves (normal, exponential, and gamma) are more realistic because they do not have an upper bound. For most data sets, the gamma will probably fit best, but if your data set is small, it may be very hard to see much of a difference between the curves.

5. $\checkmark$ Using the best-fitting distribution, go back to the code and get the maximum likelihood parameters. Use those to simulate a new data set, with the same length as your original vector, and plot that in a histogram and add the probability density curve. Right below that, generate a fresh histogram plot of the original data, and also include the probability density curve. 

How do the two histogram profiles compare? Do you think the model is doing a good job of simulating realistic data that match your original measurements? Why or why not?

If you have entered a large data frame with many columns, try running all of the code on a different variable to see how the simulation performs.

Once we get a little bit more R coding under our belts, we will return to the problem of simulating data and use some of this code again.

___



## Open libraries

```{r}
library(ggplot2) # for graphics
require(dplyr) # for filter and %>% function
library(MASS) # for maximum likelihood estimation
```

## Read in data vector

To illustrate, we will generate some fake data here:

```{r}
z <- read.table("/Users/tsoleary/R/rna_seq/cahan/results/Dm_cahan_deg_hot_results_with_norm.csv", header = TRUE, sep = ",",
                stringsAsFactors = FALSE)

# filter out the missing values
z <- z %>%
  filter(log2FoldChange > 0 & padj < 0.01) %>% 
  mutate(log2FoldChange = abs(log2FoldChange))

str(z)
summary(z)
```

In the third step of this exercise, you wil substitute in your own data for this fake data set. $\checkmark$ But for now, use the code chunks below to see how you fit different statistical distributions to a vector of observations, and then estimate the maximum likelihood parameters for each distribution.

## Plot histogram of data

Plot a histogram of the data, using a modification of the code from lecture. Here we are switching from `qplot` to `ggplot` for more graphics options. We are also rescaling the y axis of the histogram from counts to density, so that the area under the histogram equals 1.0.

```{r}
p1 <- ggplot(data=z, aes(x=log2FoldChange, y=..density..)) +
  geom_histogram(color="grey60",fill="cornsilk",size=0.2) 
print(p1)
```

## Add empirical density curve

Now modify the code to add in a kernel density plot of the data. This is an empirical curve that is fitted to the data. It does not assume any particular probability distribution, but it smooths out the shape of the histogram:

```{r}
p1 <-  p1 +  geom_density(linetype="dotted",size=0.75)
print(p1)
```

## Maximum likelihood params for `normal`

Next, fit a normal distribution to your data and grab the maximum likelihood estimators of the two parameters of the normal, the mean and the variance:

```{r}
normPars <- fitdistr(z$log2FoldChange,"normal")
print(normPars)
str(normPars)
normPars$estimate["mean"] # note structure of getting a named attribute

```
## Plot `normal` probability density

Now let's call the `dnorm` function inside ggplot's `stat_function` to generate the probability density for the normal distribution. Read about `stat_function` in the help system to see how you can use this to add a smooth function to any ggplot. Note that we first get the maximum likelihood parameters for a normal distribution fitted to thse data by calling `fitdistr`. Then we pass those parameters (`meanML` and `sdML` to `stat_function`:

```{r}

meanML <- normPars$estimate["mean"]
sdML <- normPars$estimate["sd"]

xval <- seq(0,max(z$log2FoldChange),len=length(z$log2FoldChange))

 stat <- stat_function(aes(x = xval, y = ..y..), fun = dnorm, colour="red", n = length(z$log2FoldChange), args = list(mean = meanML, sd = sdML))
 p1 + stat
```

Notice that the best-fitting normal distribution (red curve) for these data actually has a biased mean. That is because the data set has no negative values, so the normal distribution (which is symmetric) is not working well.

## Plot `exponential` probability density

Now let's use the same template and add in the curve for the exponential:

```{r}
expoPars <- fitdistr(z$log2FoldChange,"exponential")
rateML <- expoPars$estimate["rate"]

stat2 <- stat_function(aes(x = xval, y = ..y..), fun = dexp, colour="blue", n = length(z$log2FoldChange), args = list(rate=rateML))
 p1 + stat + stat2
```

## Plot `uniform` probability density

For the uniform, we don't need to use `fitdistr` because the maximum likelihood estimators of the two parameters are just the minimum and the maximum of the data:

```{r}
stat3 <- stat_function(aes(x = xval, y = ..y..), fun = dunif, colour="darkgreen", n = length(z$log2FoldChange), args = list(min=min(z$log2FoldChange), max=max(z$log2FoldChange)))
 p1 + stat + stat2 + stat3
```


## Plot `gamma` probability density


```{r}
gammaPars <- fitdistr(z$log2FoldChange,"gamma")
shapeML <- gammaPars$estimate["shape"]
rateML <- gammaPars$estimate["rate"]

stat4 <- stat_function(aes(x = xval, y = ..y..), fun = dgamma, colour="brown", n = length(z$log2FoldChange), args = list(shape=shapeML, rate=rateML))
 p1 + stat + stat2 + stat3 + stat4
```


## Plot `beta` probability density
This one has to be shown in its own plot because the raw data must be rescaled so they are between 0 and 1, and then they can be compared to the beta.

```{r}

pSpecial <- ggplot(data=z, aes(x=log2FoldChange/(max(log2FoldChange + 0.1)), y=..density..)) +
  geom_histogram(color="grey60",fill="cornsilk",size=0.2) + 
  xlim(c(0,1)) +
  geom_density(size=0.75,linetype="dotted")

betaPars <- fitdistr(x=z$log2FoldChange/max(z$log2FoldChange + 0.1),start=list(shape1=1,shape2=2),"beta")
shape1ML <- betaPars$estimate["shape1"]
shape2ML <- betaPars$estimate["shape2"]

statSpecial <- stat_function(aes(x = xval, y = ..y..), fun = dbeta, colour="orchid", n = length(z$log2FoldChange), args = list(shape1=shape1ML,shape2=shape2ML))
pSpecial + statSpecial
```


# Simulating Data Distributions

Using the best-fitting distribution, go back to the code and get the maximum likelihood parameters. Use those to simulate a new data set, with the same length as your original vector, and plot that in a histogram and add the probability density curve. Right below that, generate a fresh histogram plot of the original data, and also include the probability density curve.  $\checkmark$

## Simulating the `gamma` distribution

```{r}
gammaPars <- fitdistr(z$log2FoldChange,"gamma")
str(gammaPars)

z$sim_data <- rgamma(length(z$log2FoldChange), 
                     shape = gammaPars$estimate["shape"],
                     rate = gammaPars$estimate["rate"])

plot_sim_data <- ggplot(data=z, aes(x=sim_data, y=..density..)) +
  geom_histogram(color="grey60",fill="cornsilk",size=0.2) 

xval <- seq(0,max(z$log2FoldChange),len=length(z$log2FoldChange))

stat_g <- stat_function(aes(x = xval, y = ..y..), 
                        fun = dgamma, colour="brown", 
                        n = length(z$log2FoldChange), 
                        args = list(shape=gammaPars$estimate["shape"],
                                    rate=gammaPars$estimate["rate"]))

plot_sim_data + stat_g
```


## Plot a fresh histogram of the original data

```{r}
p1 <- ggplot(data=z, aes(x=log2FoldChange, y=..density..)) +
  geom_histogram(color="grey60",fill="cornsilk",size=0.2) 
p1 + stat_g
```

How do the two histogram profiles compare? Do you think the model is doing a good job of simulating realistic data that match your original measurements? Why or why not?

The model is certianly doing a good job of simulating the data realistically. Both the simulated histogram and the real data histogram look almost identical. That is probably because I have so many observations (> 2,000). So the simulated data is easier to match when there are that many observations.